% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
%\documentclass[conference]{IEEEtran}
\documentclass[conference,12pt,draftclsnofoot,onecolumn]{IEEEtran}
% Add the compsoc option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

\usepackage{lineno}
\linenumbers



% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
\usepackage[justification=justified]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
\bibliographystyle{IEEEtran}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Ultra Low Bandwidth Video Surveillance System}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Pratyush Anand, Prof. Subrat Kar$^*$}
\IEEEauthorblockA{Dept. of Electrical Engineering,\\
 Indian Institute of Technology Delhi, \\
Hauz Khas, New Delhi \\
email: eey107515@ee.iitd.ac.in, subrat@ee.iitd.ac.in}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
%\boldmath
For a video surveillance system, image transfer over a low bandwidth
channel has always been challenging task. Specially, if image is taken
from a live camera and it has to be transmitted over a wireless delay
tolerant network, then the task is twisted a bit more.Complexity
increases further, if we need to build a viable low cost system with a
low power solution. Such solution is only possible if we extract only
relevant information from the video frame and transmit it over the
network.This work is an attempt to frame such a low data rate
image pipeline with considerably minimal computational cost.
We are stripping down each moving object to few pixel,
mainly the skeleton endpoints and then also recognize moving
object based on motion information.We have also compared execution time
of our pipeline with some other implementations.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the conference you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals/conferences frown on
% math in the abstract anyway.

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
Image based surveillance systems are ubiquitous, still number of such
nodes are increasing everyday. Most of them transmit compressed video
frames to a base station, where it is monitored by a person or a group
of person. But such an arrangement can not be foolproof. So, any
attempt in the direction of its automation can be of great use in
application areas, such as traffic monitoring, elderly care, security
etc.\\
\indent There had been lot of advancement with low power wireless home
network eg. ZigBee, DASH-7 etc which are used in smart home
technologies. Video surveillance system can be integrated with existing
home network, but it will be very important to achieve, reduction in
amount of data to be transmitted due to lack of end to end
connectivity.A low data rate node will also allow the system to remain
in sleep mode for longer duration and hence to have longer battery
life.\\
\indent For surveillance data, entire image need not be transmitted.
Only a few segments of image need to be transmitted(the fast changing
scenes).Transmitting only significant features pre-extracted locally
from the image can reduce transmission requirement
significantly.However, we will need to ensure that this minimization of
content allows us to reconstruct the image with relevant details at the
other end.Extraction of such image information is possible if end node
is intelligent. If we go to the level of extracting semantic information
from deduced features, then it can reduce data rate even further.\\
\indent Automatic analysis of scene and then to infer desired
information out of it can be a lot complex because of the complexity of
the scene, specially when application is targeted for outdoor
monitoring.  Sometime background of the scene can be moving, while in
some other scene ambient light can be different. Similarly there, can be
many other hurdles in the process of automation. But if an efficient
background detection algorithm is chosen then, these issues can be
addressed up to a lot extent. Care must be taken in selecting algorithm,
so that it allows information extraction almost in real time. With
latest research in computer vision ~\cite{3} ~\cite{5}, it seems that
such task could be viable with low cost embedded system.\\
\indent This works has been done by choosing one of best background
subtraction algorithm. Skeletonization and further information about
selected object ontology has been used as the recognition method.When
object is at distance from the camera then motion features are very
helpful in object recognition. 
\indent Organization of the paper is as follows: In the next section we
provide a survey of related work done in recent past. After this, we
have provided our proposed framework, followed by result and conclusion.
At the end, we have also provided future work to be done in this line.


\section{Related Work}
% no \IEEEPARstart
The most difficult part of such implementation is to find an
efficient background estimation algorithm so that moving scene can be
extracted. Features such as Gradient histogram, Gray Scale (Haar),
color, texture, self-similarity and motion have been used by different
researchers. \\ \indent ~\cite{1} and many other have used color
information as the feature for background estimation. But only color as
feature might not be sufficient ~\cite{2} in surveillance applications
where image resolution is very low.  Adding motion along with image
intensities gives better result in moving bodies estimation. When
background color is same as foreground color then texture features
represented by local binary pattern ~\cite{3} provides interestingly
nice result. Further, features computed at a single scale can be used to
approximate feature at nearby scale. Such implementations ~\cite{4}
accelerates the execution for practical applications.Methods based on
Gaussian Mixtures Model(GMM) have also been widely used, but they are
computationally very expensive.  There is one non-parametric
implementation ~\cite{5} known as Vibe, which decides about background
pixel value after comparison with closest samples selected
randomly.Interesting part of this approach is that background model is
getting initialized from a single frame itself.\\ \indent Once we have
identified the foreground moving part, next important task is to reduce
it's size or extract minimal useful information out of it. So far,
object based video coding such as ~\cite{7}, ~\cite{8} seems to be the
best compression techniques.  Commercial algorithms such as MPEG-4 also
employees object based coding.Applications which we have targeted in
this work is to identify moving with minimal computational cost.Shape or
skeleton ~\cite{11} based based approach seems computationally efficient
for object recognition.  Medial axis transform, distance transform,
morphological and star skeletonization etc ~\cite{9} ~\cite{10} are
different methods which can be used to find out skeleton of a moving
object.\\


\section{Proposed Framework}
% no \IEEEPARstart
We have implemented our pipeline in C and on Linux platform, so that it
can easily be ported from a PC to embedded environment. Wherever
possible, we have used opencv library to carry intended job. Our top
level pipeline can be explained as in figure ~\ref{image_pipeline}.
\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{figures/image_pipeline}
\caption{Low BW surveillance Image Pipeline}
\label{image_pipeline}
\end{figure}


Since background subtraction has key role in accomplishing intended job,
therefore we have compared two recently developed efficient background
subtraction algorithm and then choosed one of them in our final
work.First one ~\cite{3} is based on use of texture features present in
Local Binary Pattern(LBP). LBP works well with local illumination
changes, however there can be issues in case of global illumination
change.Author of this paper has done several improvements by using
photometric invariant color measurement and flexible weight updating for
background modes. However, computationally it is not so efficient
compared to second one ~\cite{5} which we have also selected for our
uses.  It is based on unique way of replacing background pixel value
over the time.It replaces background values for last N frames
randomly.Furthermore, it diffuses updated values to neighbouring pixels,
and again that too on random basis. So far selected algorithm surpasses
other existing algorithm in computation complexities. Figure
\ref{bg_compare} shows the comparison of execution time of these two
algorithm.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{figures/bg_compare}
\caption{Variation of background subtraction execution time of ~\cite{3}
and ~\cite{5} with frame number. This timing was observed with a system
having having DMIPS = 800.}
\label{bg_compare}
\end{figure}

None of the background subtraction algorithm allows pure foreground
extraction. There would always be several noise object in the extracted
image. These are cleaned by morphological erosion operation followed by
dilation operation.Further all moving contours are separated out by
using opencv library ~\cite{12} function cvFindContours.This function
gives us boundary point of moving object.

Star skeletonization method has been used to find extreme point on
moving contours. This method plots distance of each boundary point from
the centroid and then uses peaks of the curve as skeleton
point.Following steps have been used to identify types of each moving
contours.
\begin{enumerate}
\item Centroid of each object is found out using following formula.\\
	\begin{equation}
	C_x = {1 \over N} \Sigma ^N _{i = 1} X_i 
	\end{equation}
	\begin{equation}
	C_y = {1 \over N} \Sigma ^N _{i = 1} Y_i 
	\end{equation}
Here X$_i$ and Y$_i$ are (X,Y) co-ordinate of i$_{th}$ point on the contour
boundary.
\item Distance d$_i$ is calculated between centroid and each boundary
point as follows.This calculated distance vector are stored in a CvMat
array.
	\begin{equation}
	d_i = \sqrt{(C_x - X_i)^2 + (C_y - Y_i)^2}
	\end{equation}

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{figures/distance}
\caption{Distance plot of human contour points from its centroid}
\label{distance}
\end{figure}

\item Distance vector array is smoothed to remove noise peaks using
cvSmooth.If these distances are plotted then it looks like fig
\ref{distance}. Now local maxima of distance vector is
calculated by finding zero crossing of difference vectors.\\ However,
even after smoothing operation there are some peaks which is not of our
interest.In our algorithm, we are using 2 most relevant peaks which are
nearest to each bottom corner of bounding box of contour respectively.
Only these two peaks along with centroid will give us sufficient information
to distinguish human among human, vehicle or animal etc.\\
In case of human these two peaks depicts two legs.For vehicle these are
just two extrema points of lower portion of back and front.In case of
animal these will correspond to front first leg and back last leg.
\item Let P$_1$(X$_1$, Y$_1$), P$_2$(X$_2$, Y$_2$) and C(C$_x$, C$_y$) are two peaks
nearest to bottom right and bottom left corner and centroid
respectively. Let $\theta$ is the angle between P$_1$C and P$_2$C, then
$\theta$ can be calculated as follows.\\
%
	\begin{equation}
	\theta = tan^{-1}[(Y_2 - C_y) / (X_2 - C_x)] \\ - tan^{-1}[(Y_1 - C_y) / (X_1 - C_x)]
	\end{equation}
%
If variation of this $\theta$ is plotted in respective frames for human
and vehicle then it looks like as shown in fig \ref{angle_plot}. There
are few points noticeable in the plot for human. First that, angle
variation pattern is repeatable. Second, It touches to 0 at some point.
For vehicle, it is almost constant as expected. We have not tried with a
video with animal. But, for animal there would be variation with
repeatable pattern but would never touch to zero.These criterion can be
the basis to identify about an object, whether it is a human, vehicle or
animal.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.35]{figures/angle_plot}
\caption{Variation of angle between legs with frame number for human and
vehicle.}
\label{angle_plot}
\end{figure}

\item We create a linked list of objects. When a new object comes in the
view of camera, a structure is created and added to the list.This new
object is tracked and value of (C$_x$, C$_y$), $\theta$ in each frame is
stored. 
\begin{enumerate} 
\item We track value of $\theta$ until it goes to '0' three times.
\item Now consider $\theta$ values between first and second '0' as
vector T$_1$ and $\theta$ values between second and third '0' as vector
T$_2$.
\item Find mean m$_1$ and m$_2$ of vector T$_1$ and T$_2$ respectively.
\item If n is the length of vector T$_1$ then calculate correlation value
between these two vectors to find similarities as follows.
	\begin{equation}
	corel = {{\Sigma ^n _{i = 1}(T_{1i} - m_1) * (T_{2i} - m_2)}
\over {\sqrt {\Sigma ^n _{i = 1} (T_{1i} - m_1)^2 * \Sigma ^n _{i = 1} (T_{2i}
- m_2)^2}}}
	\end{equation}
\item If correlation value is greater than a threshold value TH$_1$ then we say
that it is a human.

\end{enumerate} 
\end{enumerate}
\section{Results}
% no \IEEEPARstart
We observe that with our implementation, code is able to detect a moving
person after it's 3 steps move. Figure  \ref{pipeline_images} shows
output images at different stages of pipeline.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.30]{figures/pipeline_images}
\caption{Images at different stage of pipeline. (From top left in
clockwise order) \textbf{a.} Gray Scale input frame to pipeline
\textbf{b.}Foreground extracted image using Vibe \textbf{c.} Cleaned
image \textbf{d.} Contour of moving object \textbf{e.} Plot of 3 points
of interest, centroid and two distance peaks nearer to bottom left and
bottom right corner of bounding box \textbf{f.} Virtual representation
of scene} 
\label{pipeline_images}
\end{figure}

We have also done experiments with negative images like a person moving
on bicycle, or a vehicle moving on road. Our algorithm is successfully
able to reject these objects. Figure \ref{negative_inputs} shows that
how does this implementation rejects moving vehicle and bicycle and  does
not recognize them as human.
\begin{figure}[!h]
\centering
\includegraphics[scale=0.30]{figures/negative_inputs}
\caption{Input and output of pipeline in case of negative images}
\label{negative_inputs}
\end{figure}


Comparison of proposed framework with HAAR and IDIAP detection algorithm
in figure \ref{pipeline_execution_time} shows that, this is quite
faster. Our pipeline takes just 3.6 mS on the average, while HARR and
IDIAP takes around 20mS and 248 mS respectively per frame. This timing
was observed with a system having DMIPS = 800.

\begin{figure}[!h]
\centering
\includegraphics[scale=0.30]{figures/pipeline_execution_time}
\caption{Variation of different pipeline execution time with a system
having DMIPS=800}
\label{pipeline_execution_time}
\end{figure}

So if a surveillance application requires to identify moving person,
then we might not need to use complex algorithm. Processor like Coretx
M3/M4 are used in an embedded environment with a low power application.
Such processors have DMIPS of 1.25 dmips/Mhz. If we use such processors
at 300 MHz, our pipeline will be able to process one frame in less than
8 mS, and therefore system can go in sleep mode for longer time and
hence can save a lot of powers.

\section{Future Work}
% no \IEEEPARstart

Porting of this pipeline on an ARM platform would be a nice idea.We also
need to see that how does this pipeline behaves with exiting home
network like zigbee. Vibe algorithm has one issue that it is not able to
remove shadow.So, an improvement in Vibe for ghost and shadow removal
will make this pipeline more robust.


% An example of a floating figure using the graphicx package.
% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



\section{Conclusion}

We have taken unique property of human leg motion, that it is periodic
and also angle between two legs varies between 0 and some maximum value.
We have demonstrated that with our proposed framework one can achieve
almost real time pedestrian detection.



% conference papers do not normally have an appendix


% use section* for acknowledgement
%\section*{Acknowledgment}




% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}

%\bibitem{1}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

%\end{thebibliography}

\bibliography{references}


% that's all folks
\end{document}


